import { GoogleGenAI, Modality } from "@google/genai";

// API Key is managed externally and available as process.env.API_KEY
const ai = new GoogleGenAI({ apiKey: process.env.API_KEY! });

interface ImageInput {
  data: string; // Base64 encoded string
  mimeType: string;
}

export const generateImage = async (prompt: string, image?: ImageInput): Promise<string> => {
  try {
    // If an image is provided, use the image editing model
    if (image) {
      const response = await ai.models.generateContent({
        model: 'gemini-2.5-flash-image',
        contents: {
          parts: [
            {
              inlineData: {
                data: image.data,
                mimeType: image.mimeType,
              },
            },
            {
              text: prompt,
            },
          ],
        },
        config: {
          responseModalities: [Modality.IMAGE],
        },
      });

      // Find the image part in the response
      const imagePart = response.candidates?.[0]?.content?.parts?.find(part => part.inlineData);
      if (imagePart && imagePart.inlineData) {
        return imagePart.inlineData.data;
      } else {
        throw new Error("No image was generated by the API in the response.");
      }
    } 
    // If no image is provided, use the text-to-image model
    else {
      const response = await ai.models.generateImages({
          model: 'imagen-4.0-generate-001',
          prompt: prompt,
          config: {
            numberOfImages: 1,
            outputMimeType: 'image/png',
            aspectRatio: '1:1',
          },
      });

      if (response.generatedImages && response.generatedImages.length > 0) {
        return response.generatedImages[0].image.imageBytes;
      } else {
        throw new Error("No image was generated by the API.");
      }
    }
  } catch (error) {
    console.error("Error generating image:", error);
    // Re-throw the error to be handled by the calling function
    throw error;
  }
};
